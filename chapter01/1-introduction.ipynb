{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 第1章 はじめに"
      ],
      "metadata": {
        "id": "04lbnAjUp700"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 transformersを使って自然言語処理を解いてみよう"
      ],
      "metadata": {
        "id": "FW8T2irOZ92X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[ja,sentencepiece,torch]"
      ],
      "metadata": {
        "id": "0nHAJazMp7CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "D27ZqHlIWF8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 文書分類"
      ],
      "metadata": {
        "id": "uPib24mtqDDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_classification_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-marc_ja\"\n",
        ")\n",
        "positive_text = \"世界には言葉がわからなくても感動する音楽がある。\"\n",
        "# positive_textの極性を予測\n",
        "print(text_classification_pipeline(positive_text)[0])"
      ],
      "metadata": {
        "id": "NZkuITLG3P12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# negative_textの極性を予測\n",
        "negative_text = \"世界には言葉がでないほどひどい音楽がある。\"\n",
        "print(text_classification_pipeline(negative_text)[0])"
      ],
      "metadata": {
        "id": "mcZJ5gev3RBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 自然言語推論"
      ],
      "metadata": {
        "id": "KfM5ymhA1K_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nli_pipeline = pipeline(model=\"llm-book/bert-base-japanese-v3-jnli\")\n",
        "text = \"二人の男性がジェット機を見ています\"\n",
        "entailment_text = \"ジェット機を見ている人が二人います\"\n",
        "\n",
        "# textとentailment_textの論理関係を予測\n",
        "print(nli_pipeline({\"text\": text, \"text_pair\": entailment_text}))"
      ],
      "metadata": {
        "id": "fdnmgdhO3hKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contradiction_text = \"二人の男性が飛んでいます\"\n",
        "# textとcontradiction_textの論理関係を予測\n",
        "print(nli_pipeline({\"text\": text, \"text_pair\": contradiction_text}))"
      ],
      "metadata": {
        "id": "ap_L_bCj3n6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_text = \"2人の男性が、白い飛行機を眺めています\"\n",
        "# textとneutral_textの論理関係を予測\n",
        "print(nli_pipeline({\"text\": text, \"text_pair\": neutral_text}))"
      ],
      "metadata": {
        "id": "RFGjb75u3pwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.3 意味的類似度計算"
      ],
      "metadata": {
        "id": "EMLd6A6ZqFLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sim_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-jsts\",\n",
        "    function_to_apply=\"none\",\n",
        ")\n",
        "text = \"川べりでサーフボードを持った人たちがいます\"\n",
        "sim_text = \"サーファーたちが川べりに立っています\"\n",
        "# textとsim_textの類似度を計算\n",
        "result = text_sim_pipeline({\"text\": text, \"text_pair\": sim_text})\n",
        "print(result[\"score\"])"
      ],
      "metadata": {
        "id": "QnrEeVmNSLRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dissim_text = \"トイレの壁に黒いタオルがかけられています\"\n",
        "# textとdissim_textの類似度を計算\n",
        "result = text_sim_pipeline({\"text\": text, \"text_pair\": dissim_text})\n",
        "print(result[\"score\"])"
      ],
      "metadata": {
        "id": "LPceX7ro33tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "sim_enc_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-unsup-simcse-jawiki\",\n",
        "    task=\"feature-extraction\",\n",
        ")\n",
        "\n",
        "# textとsim_textのベクトルを獲得\n",
        "text_emb = sim_enc_pipeline(text, return_tensors=True)[0][0]\n",
        "sim_emb = sim_enc_pipeline(sim_text, return_tensors=True)[0][0]\n",
        "# textとsim_textの類似度を計算\n",
        "sim_pair_score = cosine_similarity(text_emb, sim_emb, dim=0)\n",
        "print(sim_pair_score.item())"
      ],
      "metadata": {
        "id": "axtkpgoNkOnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dissim_textのベクトルを獲得\n",
        "dissim_emb = sim_enc_pipeline(dissim_text, return_tensors=True)[0][0]\n",
        "# textとdissim_textの類似度を計算\n",
        "dissim_pair_score = cosine_similarity(text_emb, dissim_emb, dim=0)\n",
        "print(dissim_pair_score.item())"
      ],
      "metadata": {
        "id": "PPyQ9w9-llsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.4 固有表現認識"
      ],
      "metadata": {
        "id": "Yy836I6G1N2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "ner_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-ner-wikipedia-dataset\",\n",
        "    aggregation_strategy=\"simple\",\n",
        ")\n",
        "text = \"大谷翔平は岩手県水沢市出身のプロ野球選手\"\n",
        "# text中の固有表現を抽出\n",
        "pprint(ner_pipeline(text))"
      ],
      "metadata": {
        "id": "RQisi4M5pDSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.5 要約生成"
      ],
      "metadata": {
        "id": "NvEGn3uN1QuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2text_pipeline = pipeline(\n",
        "    model=\"llm-book/t5-base-long-livedoor-news-corpus\"\n",
        ")\n",
        "article = \"ついに始まった３連休。テレビを見ながら過ごしている人も多いのではないだろうか？　今夜オススメなのは何と言っても、NHKスペシャル「世界を変えた男 スティーブ・ジョブズ」だ。実は知らない人も多いジョブズ氏の養子に出された生い立ちや、アップル社から一時追放されるなどの経験。そして、彼が追い求めた理想の未来とはなんだったのか、ファンならずとも気になる内容になっている。 今年、亡くなったジョブズ氏の伝記は日本でもベストセラーになっている。今後もアップル製品だけでなく、世界でのジョブズ氏の影響は大きいだろうと想像される。ジョブズ氏のことをあまり知らないという人もこの機会にぜひチェックしてみよう。 世界を変えた男　スティーブ・ジョブズ（NHKスペシャル）\"\n",
        "# articleの要約を生成\n",
        "print(text2text_pipeline(article)[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "GvKcGPGio9ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 transformersの基本的な使い方"
      ],
      "metadata": {
        "id": "2rsE2WYDp2g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# AutoTokenizerでトークナイザをロードする\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"abeja/gpt2-large-japanese\")\n",
        "# 入力文をトークンに分割する\n",
        "tokenizer.tokenize(\"今日は天気が良いので\")"
      ],
      "metadata": {
        "id": "8KpsxTQ1o-D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# 生成を行うモデルであるAutoModelForCausalLMを使ってモデルをロードする\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"abeja/gpt2-large-japanese\"\n",
        ")\n",
        "# トークナイザを使ってモデルへの入力を作成する\n",
        "inputs = tokenizer(\"今日は天気が良いので\", return_tensors=\"pt\")\n",
        "# 後続のテキストを予測\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_length=15,  # 生成する最大トークン数を15に指定\n",
        "    pad_token_id=tokenizer.pad_token_id  # パディングのトークンIDを指定\n",
        ")\n",
        "# generate関数の出力をテキストに変換する\n",
        "generated_text = tokenizer.decode(\n",
        "    outputs[0], skip_special_tokens=True\n",
        ")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "EWamognKp0Jt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}