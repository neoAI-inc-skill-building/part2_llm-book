{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5e78169d",
      "metadata": {
        "id": "5e78169d"
      },
      "source": [
        "# 第9章 質問応答\n",
        "## 9.3 ChatGPTにクイズを答えさせる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef865e6",
      "metadata": {
        "id": "bef865e6"
      },
      "outputs": [],
      "source": [
        "!pip install \"datasets==2.19.1\" \"huggingface_hub<0.26\" openai==0.27 tiktoken tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f83d16",
      "metadata": {
        "id": "10f83d16"
      },
      "source": [
        "### 9.3.1 OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f15639c",
      "metadata": {
        "id": "7f15639c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 取得したAPIキーに置き換えてください\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c8ee83",
      "metadata": {
        "id": "13c8ee83"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# ChatGPTに送るメッセージ\n",
        "messages = [{\"role\": \"user\", \"content\": \"日本で一番高い山は何？\"}]\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.0,\n",
        ")\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc51c22",
      "metadata": {
        "id": "fcc51c22"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"日本で一番高い山は何？\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"日本で一番高い山は富士山です。\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"一つ前の発言をひらがなに変換してください。\",\n",
        "    },\n",
        "]\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.0,\n",
        ")\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21505128",
      "metadata": {
        "id": "21505128"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"数字を1から10まで読み上げてください。\",\n",
        "    }\n",
        "]\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.0,\n",
        "    max_tokens=1,\n",
        ")\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2768663",
      "metadata": {
        "id": "f2768663"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"数字を1から10まで読み上げてください。\",\n",
        "    }\n",
        "]\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.0,\n",
        "    stop=\"5\",\n",
        ")\n",
        "print(completion[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ef6cd70",
      "metadata": {
        "id": "3ef6cd70"
      },
      "source": [
        "### 9.3.2 効率的なリクエストの送信"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0efaad",
      "metadata": {
        "id": "ff0efaad"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from typing import Awaitable, Callable, TypeVar\n",
        "from openai.error import OpenAIError\n",
        "\n",
        "T = TypeVar(\"T\")\n",
        "\n",
        "async def retry_on_error(\n",
        "    openai_call: Callable[[], Awaitable[T]],\n",
        "    max_num_trials: int = 5,\n",
        "    first_wait_time: int = 10,\n",
        ") -> Awaitable[T]:\n",
        "    \"\"\"OpenAI API使用時にエラーが返ってきた場合に再試行する\"\"\"\n",
        "    for i in range(max_num_trials):\n",
        "        try:\n",
        "            # 関数を実行する\n",
        "            return await openai_call()\n",
        "        except OpenAIError as e:\n",
        "            # 試行回数が上限に達したらエラーを送出\n",
        "            if i == max_num_trials - 1:\n",
        "                raise\n",
        "            print(f\"エラーを受け取りました：{e}\")\n",
        "            wait_time_seconds = first_wait_time * (2**i)\n",
        "            print(f\"{wait_time_seconds}秒待機します\")\n",
        "            await asyncio.sleep(wait_time_seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740063eb",
      "metadata": {
        "id": "740063eb"
      },
      "outputs": [],
      "source": [
        "async def _async_batch_run_chatgpt(\n",
        "    messages_list: list[list[dict[str, str]]],\n",
        "    temperature: float,\n",
        "    max_tokens: int | None,\n",
        "    stop: str | list[str] | None,\n",
        ") -> list[str]:\n",
        "    \"\"\"OpenAI APIに並列してリクエストを送る\"\"\"\n",
        "    # コルーチンオブジェクトをtasksに格納\n",
        "    tasks = [\n",
        "        retry_on_error(\n",
        "            # ラムダ式で無名関数を定義して渡し、\n",
        "            # retry_on_error関数の内部で呼び出させる\n",
        "            openai_call=lambda x=ms: openai.ChatCompletion.acreate(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=x,\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens,\n",
        "                stop=stop,\n",
        "            )\n",
        "        )\n",
        "        for ms in messages_list\n",
        "    ]\n",
        "    # tasks内の非同期処理を実行し結果を収集\n",
        "    completions = await asyncio.gather(*tasks)\n",
        "    return [\n",
        "        c[\"choices\"][0][\"message\"][\"content\"] for c in completions\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e7f917",
      "metadata": {
        "id": "01e7f917"
      },
      "outputs": [],
      "source": [
        "def batch_run_chatgpt(\n",
        "    messages_list: list[list[dict[str, str]]],\n",
        "    temperature: float = 0.0,\n",
        "    max_tokens: int | None = None,\n",
        "    stop: str | list[str] | None = None,\n",
        ") -> list[str]:\n",
        "    \"\"\"非同期処理関数を実行するためのラッパー\"\"\"\n",
        "    return asyncio.run(\n",
        "        _async_batch_run_chatgpt(\n",
        "            messages_list, temperature, max_tokens, stop\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678f9ad5",
      "metadata": {
        "id": "678f9ad5"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aab18a8",
      "metadata": {
        "id": "6aab18a8"
      },
      "source": [
        "### 9.3.3 クイズ用のプロンプトの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b098670",
      "metadata": {
        "id": "1b098670"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "class PromptMaker(metaclass=ABCMeta):\n",
        "    \"\"\"クイズ用プロンプトを作成するための抽象クラス\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def run(self, questions: list[str]) -> list[str]:\n",
        "        \"\"\"プロンプトの作成（具体的な実装は継承先で行われる）\"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7bc777",
      "metadata": {
        "id": "2b7bc777"
      },
      "outputs": [],
      "source": [
        "class SimplePromptMaker(PromptMaker):\n",
        "    \"\"\"単純なクイズ用プロンプトを作成するクラス\"\"\"\n",
        "\n",
        "    def run(self, questions: list[str]) -> list[str]:\n",
        "        \"\"\"プロンプトの作成\"\"\"\n",
        "        return [\n",
        "            \"あなたには今からクイズに答えてもらいます。\"\n",
        "            \"問題を与えますので、その解答のみを簡潔に出力してください。\\n\"\n",
        "            f\"問題：{q}\\n\"\n",
        "            \"解答：\"\n",
        "            for q in questions\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12f6965",
      "metadata": {
        "id": "f12f6965"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"日本で一番高い山は何？\",\n",
        "    \"日本で一番長い川は何？\",\n",
        "    \"日本で一番面積の大きい都道府県はどこ？\",\n",
        "    \"日本で一番人口の多い都道府県はどこ？\",\n",
        "]\n",
        "simple_prompt_maker = SimplePromptMaker()\n",
        "print(simple_prompt_maker.run(questions)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5edf3b56",
      "metadata": {
        "id": "5edf3b56"
      },
      "outputs": [],
      "source": [
        "answers = batch_run_chatgpt(\n",
        "    [\n",
        "        [{\"role\": \"user\", \"content\": p}]\n",
        "        for p in simple_prompt_maker.run(questions)\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e885c4",
      "metadata": {
        "id": "08e885c4"
      },
      "source": [
        "### 9.3.4 API使用料金の見積もり"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18730806",
      "metadata": {
        "id": "18730806"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "encoding.encode(\"日本で一番高い山は何？\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "src = hf_hub_download(\"llm-book/aio\", \"aio.py\", repo_type=\"dataset\")\n",
        "\n",
        "with open(src, \"rb\") as f:\n",
        "    code = f.read().decode(\"latin-1\")\n",
        "fixed_path = \"/tmp/aio_utf8.py\"\n",
        "with open(fixed_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "from datasets import load_dataset\n",
        "quiz_dataset = load_dataset(fixed_path, split=\"validation\", trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "_aeEO67sYkak"
      },
      "id": "_aeEO67sYkak",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79045d3b",
      "metadata": {
        "id": "79045d3b"
      },
      "outputs": [],
      "source": [
        "def calculate_prompt_cost(\n",
        "    prompts: list[str],\n",
        "    num_output_tokens: int = 40,\n",
        "    model: str = \"gpt-3.5-turbo\",\n",
        "    usd_per_token: float = 0.0015 / 1000,\n",
        "):\n",
        "    \"\"\"\n",
        "    プロンプトをOpenAI APIに送信した際にかかる費用を見積もる\n",
        "    \"\"\"\n",
        "    # トークナイザの初期化\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "\n",
        "    # 入力プロンプトの合計トークン数を算出\n",
        "    total_num_prompt_tokens = 0\n",
        "    for prompt in prompts:\n",
        "        total_num_prompt_tokens += len(encoding.encode(prompt))\n",
        "\n",
        "    avg_num_prompt_tokens = total_num_prompt_tokens / len(prompts)\n",
        "    print(\n",
        "        \"入力プロンプトの平均トークン数:\"\n",
        "        f\" {int(avg_num_prompt_tokens)}\"\n",
        "    )\n",
        "\n",
        "    # モデル出力の合計トークン数を見積もる\n",
        "    total_num_output_tokens = num_output_tokens * len(prompts)\n",
        "\n",
        "    # 費用の計算\n",
        "    total_cost = (\n",
        "        total_num_prompt_tokens + total_num_output_tokens\n",
        "    ) * usd_per_token\n",
        "    print(f\"合計コスト: {round(total_cost, 3)} USD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af21c188",
      "metadata": {
        "id": "af21c188"
      },
      "outputs": [],
      "source": [
        "questions = quiz_dataset[\"question\"]\n",
        "prompts = simple_prompt_maker.run(questions)\n",
        "calculate_prompt_cost(prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c80509d9",
      "metadata": {
        "id": "c80509d9"
      },
      "source": [
        "### 9.3.5 クイズデータセットによる評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60c988f4",
      "metadata": {
        "id": "60c988f4"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_chatgpt_outputs_for_quiz(\n",
        "    quiz_prompt_maker: PromptMaker,\n",
        "    quiz_dataset: Dataset,\n",
        "    batch_size: int,\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    クイズ用のプロンプトを使用した際の\n",
        "    データセットの各問題に対するモデルの解答を集める\n",
        "    \"\"\"\n",
        "    output_answers: list[str] = []\n",
        "    with tqdm(total=len(quiz_dataset)) as pbar:\n",
        "        for batch in quiz_dataset.iter(batch_size=batch_size):\n",
        "            # 入力の準備\n",
        "            prompts = quiz_prompt_maker.run(batch[\"question\"])\n",
        "            inputs = [\n",
        "                [{\"role\": \"user\", \"content\": p}] for p in prompts\n",
        "            ]\n",
        "\n",
        "            # APIにリクエストを送信\n",
        "            answers = batch_run_chatgpt(inputs)\n",
        "\n",
        "            # モデルの解答を表示\n",
        "            for question, answer in zip(batch[\"question\"], answers):\n",
        "                print(f\"問題：{question}\")\n",
        "                print(f\"解答：{answer}\")\n",
        "                print()\n",
        "\n",
        "            output_answers += answers\n",
        "            pbar.update(len(answers))\n",
        "    return output_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05fec382",
      "metadata": {
        "id": "05fec382"
      },
      "outputs": [],
      "source": [
        "def calculate_quiz_accuracy(\n",
        "    output_answers: list[str], correct_answers_list: list[list[str]]\n",
        ") -> float:\n",
        "    \"\"\"モデルの解答と正解の解答例から正解率を算出する\"\"\"\n",
        "    num_correct = 0\n",
        "    for output_answer, answers in zip(\n",
        "        output_answers, correct_answers_list\n",
        "    ):\n",
        "        # モデルの出力が解答例を一つでも含んでいれば正解とみなす\n",
        "        num_correct += int(any(a in output_answer for a in answers))\n",
        "    return num_correct / len(output_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738116f8",
      "metadata": {
        "id": "738116f8"
      },
      "outputs": [],
      "source": [
        "output_answers = get_chatgpt_outputs_for_quiz(\n",
        "    simple_prompt_maker, quiz_dataset, batch_size=4\n",
        ")\n",
        "accuracy = calculate_quiz_accuracy(\n",
        "    output_answers, [item[\"answers\"] for item in quiz_dataset]\n",
        ")\n",
        "print(f\"正解率：{accuracy * 100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78716567",
      "metadata": {
        "id": "78716567"
      },
      "source": [
        "### 9.3.6 文脈内学習"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_train_dataset = load_dataset(fixed_path, split=\"train\", trust_remote_code=True)\n",
        "quiz_valid_dataset = load_dataset(fixed_path, split=\"validation\", trust_remote_code=True)\n",
        "\n",
        "num_in_context_examples = 3\n",
        "in_context_examples = [quiz_train_dataset[i] for i in range(num_in_context_examples)]\n",
        "\n",
        "for ex in in_context_examples:\n",
        "    print(f'問題：{ex[\"question\"]}')\n",
        "    print(f'解答：{ex[\"answers\"][0]}')\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "max_answer_length = 0\n",
        "for answers in quiz_valid_dataset[\"answers\"]:\n",
        "    for ans in answers:\n",
        "        max_answer_length = max(max_answer_length, len(enc.encode(ans)))\n",
        "print(\"max_answer_length:\", max_answer_length)"
      ],
      "metadata": {
        "id": "fwR9Cd-JbhHL"
      },
      "id": "fwR9Cd-JbhHL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c59dead",
      "metadata": {
        "id": "1c59dead"
      },
      "outputs": [],
      "source": [
        "class InContextPromptMaker(PromptMaker):\n",
        "    \"\"\"文脈内学習を用いたクイズ用プロンプトを作成する\"\"\"\n",
        "\n",
        "    def __init__(self, examples: list[tuple[str, str]]):\n",
        "        self._prompt = (\n",
        "            \"あなたには今からクイズに答えてもらいます。問題を与えますので、\"\n",
        "            \"その解答のみを簡潔に出力してください。\\n\\n\"\n",
        "        )\n",
        "        for question, answer in examples:\n",
        "            self._prompt += f\"問題：{question}\\n解答：{answer}\\n\\n\"\n",
        "\n",
        "    def run(self, questions: list[str]) -> list[str]:\n",
        "        \"\"\"プロンプトの作成\"\"\"\n",
        "        prompts = [\n",
        "            self._prompt + f\"問題：{q}\\n解答：\" for q in questions\n",
        "        ]\n",
        "        return prompts\n",
        "\n",
        "q_and_a_list = [\n",
        "    (e[\"question\"], e[\"answers\"][0]) for e in in_context_examples\n",
        "]\n",
        "in_context_prompt_maker = InContextPromptMaker(q_and_a_list)\n",
        "prompt = in_context_prompt_maker.run([\"日本で一番高い山は何？\"])[0]\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d096f67",
      "metadata": {
        "id": "4d096f67"
      },
      "outputs": [],
      "source": [
        "questions = quiz_dataset[\"question\"]\n",
        "prompts = in_context_prompt_maker.run(questions)\n",
        "calculate_prompt_cost(prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6430a659",
      "metadata": {
        "id": "6430a659"
      },
      "outputs": [],
      "source": [
        "in_context_output_answers = get_chatgpt_outputs_for_quiz(\n",
        "    in_context_prompt_maker, quiz_dataset, batch_size=4\n",
        ")\n",
        "in_context_accuracy = calculate_quiz_accuracy(\n",
        "    in_context_output_answers,\n",
        "    [item[\"answers\"] for item in quiz_dataset],\n",
        ")\n",
        "print(f\"正解率：{in_context_accuracy * 100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fa2eb6c",
      "metadata": {
        "id": "4fa2eb6c"
      },
      "source": [
        "### 9.3.7 言語モデルの幻覚に注意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c197421",
      "metadata": {
        "id": "0c197421"
      },
      "outputs": [],
      "source": [
        "quiz_example = quiz_dataset[87]\n",
        "print(\"問題：\" + quiz_example[\"question\"])\n",
        "print(\"解答：\" + str(quiz_example[\"answers\"][0]) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e8f51f",
      "metadata": {
        "id": "d5e8f51f"
      },
      "outputs": [],
      "source": [
        "prompt = simple_prompt_maker.run([quiz_example[\"question\"]])[0]\n",
        "answer = batch_run_chatgpt([[{\"role\": \"user\", \"content\": prompt}]])[0]\n",
        "print(f\"SimplePromptMakerを用いたモデルの解答：{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f266fe8e",
      "metadata": {
        "id": "f266fe8e"
      },
      "outputs": [],
      "source": [
        "prompt = in_context_prompt_maker.run([quiz_example[\"question\"]])[0]\n",
        "answer = batch_run_chatgpt([[{\"role\": \"user\", \"content\": prompt}]])[0]\n",
        "print(f\"InContextPromptMakerを用いたモデルの解答：{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IK5IToTTVh3H"
      },
      "id": "IK5IToTTVh3H",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}